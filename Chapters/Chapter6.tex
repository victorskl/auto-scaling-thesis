\chapter{Conclusion}

\label{Chapter6}

\section{Conclusion}

In order to produce a reliable auto-scaling system, it is important to understand the target application well, in this case, ATHENA system as discussed in Chapter~\ref{Chapter2}. It is important step to identify which part of system component can be scaled such as ATHENA Worker. It also requires to consolidate the Stateless and Stateful of the system, so that dynamic scaling is possible, as discussed in Chapter~\ref{Chapter3}. It is also crucial to get insight of the foundation platform, Kubernetes as discussed in Chapter~\ref{Chapter4}, to configure properly, get up and running the \emph{Production Ready} cluster. 

Infrastructure scaling on cloud platform required provider specific API and technology. The containerisation deployment with Docker Swarm and Kubernetes technologies can scale across multi-clouds independently, without the need of Cloud Provider specific API.

Auto-scaling system can not meet SLO and QoS by simply relying on CPU utilisation and memory usage metrics alone. Most web and mobile applications require auto-scaling based on \textit{Requests Per Second} to handle traffic bursts and user load. With new \textbf{Custom Metrics API} feature introduced in Kubernetes, we can extend the API and expose ATHENA's metrics to Prometheus, then can be consumed by HPA controller and auto-scaled. For enterprise integration system like ATHENA, the auto scaling could be triggered by the ActiveMQ job queue length exceeding some empirical threshold, therefore, \textbf{Threshold-based Reactive approach} with \textbf{Control Theory} auto-scaling technique can be explored.

Effective monitoring and metrics scraping is the heart of the pipeline for auto-scaler to work reliably well. Auto-scaling with Kubernetes is non trivial task to setup for \emph{Production Ready} in Private Cloud, such as NeCTAR Research Cloud.


\section{Future Work}

For the future work, instrumenting ATHENA with Prometheus and exposing the right metrics can fine tune the auto-scaling to better handle bursts, high availability and QoS. We can also explore and design auto-scaling algorithm with different techniques such as Time-series Analysis for Kubernetes, as well as implementing Docker Swarm based auto-scaler.

We can also explore burstable infrastructure level scaling with OpenStack for NeCTAR and other Public Cloud Providers. Kubernetes has introduced Cloud Manager controller object to explore in this direction. For the infrastructure scaling, we can observe the metrics already produced by Kubernetes and Prometheus; and auto-scale nodes based on these metrics.

There are potential comparison and benchmarking studies that can be done within Kubernetes eco-system, such as benchmarking different Pod Networking options, comparison for reliable cluster file systems for Kubernetes, and so on. Highly Available (HA) Kubernetes cluster involves multiple Kube masters, therefore, multi-cells cluster; which is interesting space to explore as well.

As for ATHENA, the API backend need to decompose the aggregator component to become a better stateless application, so that it can be scaled well. And to explore ATHENA database stack to deploy it onto Kubernetes cluster using StatefulSet and explore clustered file system store, e.g. Cinder, CephFS, for dynamic volume provision.