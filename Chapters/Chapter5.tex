\chapter{Related Studies} 

\label{Chapter5} 

The concept of \textit{Auto-Scaling system} is not new. The early research dated back to IBM's \textbf{MAPE-K} architecture discussion in Autonomic Computing -- computing systems that can manage themselves given high-level objectives from administrators \parencite{1160055}. The paper \parencite{1160055} identified the key autonomic elements  -- Monitor, Analyse, Plan, Execute, Knowledge -- the reference model for autonomic control loop for achieving the self-managed -- self-configuration, self-optimisation, self-healing, self-protection -- autonomic computing system.

In \parencite{Chenhao}, it further identified the challenges of auto-scaler in each of the MAPE phases, and created taxonomy for auto-scaling web application in clouds. The \parencite{Chenhao} presented very broad spectrum of auto-scaling surveys -- some of the approaches such as scaling indicator and different type of metrics, resource estimation with rule and threshold based approaches, multi-tier application scaling and, container-based auto-scaler in Kubernetes are investigated in this thesis. 

Although not specific about auto-scaling, \parencite{Thai} is another good pointer on survey and taxonomy of resource optimisation for executing Bag-of-Task applications on Public Clouds -- which give some indication on tackling with ATHENA BoT worker remote job executions. The \parencite{ToosiSB18} is another influential article which discussed dynamic provision with Aneka that can be able to burst out to Public Cloud from on-premise Private Cloud (therefore, Hybrid Cloud) to off load the deadline-driven data intensive application and Big data processing. Some of which, for example, Kubernetes Pod Networking with Overlay Network can go across multi Clouds; therefore, it could configure \emph{Quality of Service for Pods}\footnote{\url{https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/}} and design burstable, auto-scalable system for compute or data processing systems.

Auto-scaling techniques discussed in \parencite{LoridoBotran} gives future exploration on auto-scaler algorithm design. According to \parencite{LoridoBotran}, Kubernetes HPA auto-scaler can classify into reactive approach where HPA implementation is a threshold-based reactive controller to automatically adjust the required resources to the application demand i.e. Control Loop or Control Theory as stated in literature. Other approaches presented are Threshold-based rules which are simple and straightforward to set scale up and scale down thresholds based on observed CPU load or average responses. Reinforcement Learning (RL) is Machine Learning based, a type of automatic decision-making approach with no priori knowledge or system model, but it may take the method to converge to an optimal policy. Queuing Theory is highly Mathematical influence approach that require to model VM, containers or application tier as a queue of requests. Time-series analysis is proactive auto-scaling approach that use the past history of a time-series to predict future values - which is very promising technique to explore and investigate with the Prometheus time-series database stack that already used in this thesis research.


%The \parencite{Arabnejad}

%Resource provisioning for data-intensive applications with deadline constraints on hybrid clouds using Aneka

%A Comparison of Reinforcement Learning Techniques for Fuzzy Cloud Auto-Scaling

%Large-scale cluster management at Google with Borg

%Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center
